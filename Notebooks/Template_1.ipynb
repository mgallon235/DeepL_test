{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c922ebf0-1afa-48b5-931b-2277b5b6cad5",
   "metadata": {},
   "source": [
    "# Deep Learning Pipeline Template (KNN & SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4981f9-25d7-4237-97de-393f0d442950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/mikelgallo/repos2/DeepL_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137c396b-fa96-4b5a-8c30-ec46a48e2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as pd\n",
    "\n",
    "#Model fitting, performance, balancing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors \n",
    "from sklearn.model_selection import train_test_split\n",
    "from Functions.helper_functions import *\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f18fb2-2cda-4dbd-9ac4-77aa92184ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining repository path\n",
    "#data_path = '/Users/mikelgallo/repos2/DeepL_test/Session 1_ Nearest Neighbors/'\n",
    "data_path = './Session 1_ Nearest Neighbors/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1b7db6-4b28-4551-b174-58c616c0c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documentation about the data\n",
    "df = pd.read_csv(data_path+'housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643b4e88-0410-4621-bec0-951210d814b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Highlevel view\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a139f99-1e7c-4049-b487-44642860b807",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a7f84-4f97-48cc-ad22-cab33ba05e32",
   "metadata": {},
   "source": [
    "### STEP 1 - Split columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a07b6f-359c-474e-8974-d3d9878dbe04",
   "metadata": {},
   "source": [
    "### Numeric columns (Continuous vs Discrete) Rough estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f1b2ed9-4223-4dd0-b189-c98015f7d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1 - Split columns into Continuous, Discrete, Categorical\n",
    "def numeric_cols(dataset):\n",
    "    numeric = dataset.select_dtypes(include = np.number).columns.tolist()\n",
    "    return numeric\n",
    "#STEP 2 - Rough Estimate of Continuous and Discrete columns\n",
    "def cont_or_disc(dataset,num):\n",
    "    dict = {}\n",
    "    numeric = numeric_cols(dataset)\n",
    "    df_numeric = dataset[numeric]\n",
    "    for i in df_numeric:\n",
    "        count = df_numeric[i].count()\n",
    "        unique_vals = len(df_numeric[i].unique())\n",
    "        type = 'Discrete' if unique_vals < num else 'Continuous'\n",
    "        dtype = df_numeric[i].dtype\n",
    "        dict[i] = [count, unique_vals, type, dtype]\n",
    "    result = pd.DataFrame.from_dict(dict,orient='index',columns=['count', 'unique_vals', 'type', 'dtype'])\n",
    "    return result\n",
    "#STEP 3 - Return column names for discrete and continuous    \n",
    "def numeric_col_split(df,num):\n",
    "    new_df = cont_or_disc(df,num)\n",
    "    cont_cols = []\n",
    "    disc_cols = []\n",
    "    for index,row in new_df.iterrows():\n",
    "        if row['type'] == 'Discrete':\n",
    "            disc_cols.append(index)\n",
    "        elif row['type'] == 'Continuous':\n",
    "            cont_cols.append(index)\n",
    "    return disc_cols, cont_cols        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53f31279-817d-4400-86d0-0d98a2f2ac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique_vals</th>\n",
       "      <th>type</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>506</td>\n",
       "      <td>504</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>506</td>\n",
       "      <td>26</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>506</td>\n",
       "      <td>76</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Discrete</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>506</td>\n",
       "      <td>81</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>506</td>\n",
       "      <td>446</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>506</td>\n",
       "      <td>356</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>506</td>\n",
       "      <td>412</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>506</td>\n",
       "      <td>9</td>\n",
       "      <td>Discrete</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>506</td>\n",
       "      <td>66</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>506</td>\n",
       "      <td>46</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>506</td>\n",
       "      <td>357</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>506</td>\n",
       "      <td>455</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medv</th>\n",
       "      <td>506</td>\n",
       "      <td>229</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  unique_vals        type    dtype\n",
       "crim       506          504  Continuous  float64\n",
       "zn         506           26  Continuous  float64\n",
       "indus      506           76  Continuous  float64\n",
       "chas       506            2    Discrete    int64\n",
       "nox        506           81  Continuous  float64\n",
       "rm         506          446  Continuous  float64\n",
       "age        506          356  Continuous  float64\n",
       "dis        506          412  Continuous  float64\n",
       "rad        506            9    Discrete    int64\n",
       "tax        506           66  Continuous    int64\n",
       "ptratio    506           46  Continuous  float64\n",
       "b          506          357  Continuous  float64\n",
       "lstat      506          455  Continuous  float64\n",
       "medv       506          229  Continuous  float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review Numeric Columns\n",
    "cont_or_disc(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99ed148d-026e-44f3-87d0-d9db1b773c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete columns:  ['chas', 'rad']\n",
      "Continuous columns:  ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'tax', 'ptratio', 'b', 'lstat', 'medv']\n"
     ]
    }
   ],
   "source": [
    "# Split Discrete and Continuous variables\n",
    "disc_cols, cont_cols = numeric_col_split(df,10)\n",
    "print('Discrete columns: ',disc_cols)\n",
    "print('Continuous columns: ', cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "504a9eb4-2e18-4334-8a16-2091b50df272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chas</th>\n",
       "      <th>rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chas    rad\n",
       "count  506.0  506.0\n",
       "mean     0.0   10.0\n",
       "std      0.0    9.0\n",
       "min      0.0    1.0\n",
       "25%      0.0    4.0\n",
       "50%      0.0    5.0\n",
       "75%      0.0   24.0\n",
       "max      1.0   24.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review Discrete variables\n",
    "df[disc_cols].describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "137a0a60-f56d-4cda-a8d3-e389bd5992d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chas\n",
      "0    471\n",
      "1     35\n",
      "Name: count, dtype: int64\n",
      "rad\n",
      "24    132\n",
      "5     115\n",
      "4     110\n",
      "3      38\n",
      "6      26\n",
      "2      24\n",
      "8      24\n",
      "1      20\n",
      "7      17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dependent variable\n",
    "print(df['chas'].value_counts())\n",
    "#Categorical variable\n",
    "print(df['rad'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0273f-a1d0-4631-a4ca-a036e0e68150",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88625f8c-b8fd-40c8-b991-b12137cfeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do we Get non-numeric columns? Categoricals\n",
    "numerics = numeric_cols(df)\n",
    "non_numeric = [col for col in df.columns if col not in numerics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e27d0cdb-9226-47a9-b73d-7526bd0dee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede6fb8-d386-466a-af68-115b939d4c53",
   "metadata": {},
   "source": [
    "#### Create a list to store the results predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03eb6cfd-c76d-4e9b-8bab-6f55d713d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store tuples with a description and the score of election)\n",
    "results = []\n",
    "\n",
    "#For each model we need to create different copies of the train Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9f597-14b8-407d-8c02-a9d7c502e75e",
   "metadata": {},
   "source": [
    "### STEP 2 - Imputing/Removing Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83c42611-20b3-42c8-9901-7bd7397340a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       0.0\n",
       "zn         0.0\n",
       "indus      0.0\n",
       "chas       0.0\n",
       "nox        0.0\n",
       "rm         0.0\n",
       "age        0.0\n",
       "dis        0.0\n",
       "rad        0.0\n",
       "tax        0.0\n",
       "ptratio    0.0\n",
       "b          0.0\n",
       "lstat      0.0\n",
       "medv       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624172a2-bd8a-48e7-b082-c63d50e0ba59",
   "metadata": {},
   "source": [
    "###### Removing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb681101-e55e-464a-9075-1a83ed82781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop all columns with X% of missing values:\n",
    "#df=df.dropna(axis=1,thresh=0.6*df.shape[0])\n",
    "# To drop a specific column then: \n",
    "#df = df.drop(['column'],axis=1)\n",
    "\n",
    "#If we want to remove rows with at least 1 missing value\n",
    "#df = df.dropna()\n",
    "# E.g. -> X_train0 = X_train.dropna(axis=0,how = \"any\") # axis=0 removes \"any\" rows with missing data\n",
    "\n",
    "\n",
    "#If we want to remove columns with at least 1 missing value\n",
    "#df = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa13b4d-8b6f-4ffc-b007-2055248743ab",
   "metadata": {},
   "source": [
    "###### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e62b5-9565-4a97-9eb3-198730c7dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####define a list of columns to impute\n",
    "#missing_cols = df.columns\n",
    "####Iterate over the list of missing columns to impute both train and test\n",
    "#for col  in missing_cols:\n",
    "    #mean = df[col].mean()\n",
    "    #df_train[col].fillna(mean,inplace=True)\n",
    "    #df_test[col].fillna(mean,inplace=True)\n",
    "\n",
    "\n",
    "#Stratified imputation\n",
    "#my_data[my_col].fillna(my_data.groupby(my_category)[my_col].transform(\"mean\"), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ba8f5-a596-4017-9b2d-bdbd67cbe030",
   "metadata": {},
   "source": [
    "### STEP 3 - Enconding / Creating Dummies and FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5285658-42dc-465a-9d05-03b25d42f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Wilderness_Area into dummies\n",
    "def encode(df, columns_hot):\n",
    "    encoded_df = pd.get_dummies(df, columns=columns_hot, dtype=float)\n",
    "    return encoded_df\n",
    "\n",
    "# Execute function for df and df_test\n",
    "#df = pd.get_dummies(df, columns=cat_feat, drop_first=False)\n",
    "#E.g. df = encode(df, ['orientation', 'neighborhood'])\n",
    "#df = encode(df, ['Wilderness_Area','Soil_Type'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6731fb2a-a630-4724-bc5f-2ab050e3c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformating if needed:\n",
    "#df['is_cover_7'] = np.where(df['Cover_Type'] == 7, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2a3f9-4efe-4a86-8814-ca79c79f7ca9",
   "metadata": {},
   "source": [
    "## DATASET Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc9808-c37b-4a49-8fca-3621021f876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# In case we use directly a Train and Test datatset\n",
    "#Xtrain = df_train.drop(['dependent'],axis = 1)\n",
    "#ytrain = df_train['dependent']\n",
    "#Xtest = df_test #probably it doesnt require to remove any column\n",
    "\n",
    "# In case we want to split again our train data in order to measure the performance of our models.\n",
    "#X_train,X_test,y_train,y_test = train_test_split(Xtrain,ytrain,test_size = 0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28697f43-80ae-4ab4-825e-19c52ae80a92",
   "metadata": {},
   "source": [
    "## Scaling (Full Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82211f76-f411-4a6b-a0a5-c3779682c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaler2 = StandardScaler()\n",
    "#scaler2.fit(Xtrain[col_cont])\n",
    "\n",
    "#Xtrain[col_cont] = scaler.transform(Xtrain[col_cont])\n",
    "#Xtest[col_cont] = scaler.transform(Xtest[col_cont])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75097a-51a7-4cb2-b25b-160fb3caef0e",
   "metadata": {},
   "source": [
    "### Scaling (Split Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e077a-939f-4031-b82e-523a0d76f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Defining continuous variables:\n",
    "#no_cont = ['Index','Soil_Type']\n",
    "#col_cont= [col for col in columns_cont if col not in no_cont] #Columns cont was defined previously\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#We will only fit our scaler object with continuous variables\n",
    "scaler.fit(X_train[col_cont])\n",
    "\n",
    "# Fiting scaler with continuos variables\n",
    "X_train[col_cont] = scaler.transform(X_train[col_cont])\n",
    "X_test[col_cont] = scaler.transform(X_test[col_cont])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a53b8b-92a7-4f5d-bea6-5a8bd5430718",
   "metadata": {},
   "source": [
    "## Running KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5e170-62cf-4839-a82a-9eacb7409904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Create an instance of the KNN model\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "KNN_model  = KNeighborsClassifier(n_neighbors=20, algorithm = 'brute')\n",
    "KNN_model.fit(Xtrain,ytrain)\n",
    "\n",
    "print(f\"Predicted class is \",KNN_model.predict(Xtest))\n",
    "\n",
    "## Check which other algorithm should we try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5450af-0ba9-4515-93ac-817079422f92",
   "metadata": {},
   "source": [
    "## Hypertuning KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418301ae-2331-4fd0-9a31-3f0fca1cba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Create an instance of the KNN model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "KNN_model  = KNeighborsClassifier(algorithm = 'brute')\n",
    "\n",
    "# Step 2 - Create our grid_search_values\n",
    "grid_values = {'n_neighbors': [5, 15, 25, 30, 35, 50], 'weights': ['uniform','distance']}\n",
    "\n",
    "# Step 3 - Instanciate our gridSearch CV\n",
    "grid_knn_acc = GridSearchCV(KNN_model, param_grid = grid_values, scoring='roc_auc',cv=20)\n",
    "\n",
    "#Step 4 - fit model \n",
    "grid_knn_acc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da75c9-6425-4af0-8229-282db9f41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report best Number of Neighbors\n",
    "GridSearch_table_plot(grid_knn_acc, \"n_neighbors\", negative=False, display_all_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6923a-7041-47cb-956f-cb8766f9f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Result\n",
    "print('best parameters:', grid_knn_acc.best_params_)\n",
    "print('best score:', grid_knn_acc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65a3a4-6dea-4b6d-86e5-4e1ba7ea9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Performance Scores\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "#InSample (Train)\n",
    "insample_y_predict = grid_knn_acc.predict(X_train)\n",
    "\n",
    "print('the accuracy score for best estimator: ', accuracy_score(y_train,insample_y_predict))\n",
    "print('the precision score for best estimator: ', precision_score(y_train,insample_y_predict))\n",
    "print('the recall score for best estimator: ', recall_score(y_train,insample_y_predict))\n",
    "print('the f1_score score for best estimator: ', f1_score(y_train,insample_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f47532-d337-426e-b150-1824e9c7a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of Sample (Test)\n",
    "y_predict = grid_knn_acc.predict(X_test)\n",
    "\n",
    "print('the accuracy score for best estimator: ', accuracy_score(y_test,y_predict))\n",
    "print('the precision score for best estimator: ', precision_score(y_test,y_predict))\n",
    "print('the recall score for best estimator: ', recall_score(y_test,y_predict))\n",
    "print('the f1_score score for best estimator: ', f1_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a093ec-b7e4-4fe7-bf25-7dc3ae90aa25",
   "metadata": {},
   "source": [
    "### Running SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a164e-f71c-40f6-9891-f4847a131b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Support Vector Machine classifier with a linear kernel\n",
    "classifier = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtain decision values or probabilities on the training set\n",
    "y_train_scores = classifier.decision_function(X_train_scaled)  # Use decision_function for linear kernel\n",
    "# Alternatively, you can use predict_proba for non-linear kernels\n",
    "# y_train_probs = classifier.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "# Calculate AUC score on the training set\n",
    "auc_score_train = roc_auc_score(y_train, y_train_scores)\n",
    "\n",
    "# Print or use the AUC score as needed\n",
    "print(\"AUC score on the training set:\", auc_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574cd64-02ea-4163-9654-923b6f093318",
   "metadata": {},
   "source": [
    "### Hypertuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87752bd8-071f-4c64-975b-805ba713cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target is continuous\n",
    "MySvr = SVR()\n",
    "grid_values = {'C':[0.01, 0.1, 1, 10], 'epsilon':[0.1, 0.5, 0.75], 'kernel':['linear', 'poly', 'rbf',]}\n",
    "grid_svr = GridSearchCV(MySvr, param_grid=grid_values, scoring='r2', cv=5, n_jobs=7)\n",
    "grid_model = grid_svr.fit(X, y)\n",
    "\n",
    "## Classification\n",
    "my_SVM_model = SVC()\n",
    "grid_values = {'C':[0.1,0.2, 0.3, 0.5, 1, 10], 'gamma':[0.25,0.5,0.75, 1, 1.25, 1.5], 'kernel':['linear', 'rbf']}\n",
    "grid_svc_acc = GridSearchCV(my_SVM_model, param_grid = grid_values,scoring = 'roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a011799-7ffb-4109-a793-6d28b414af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Results\n",
    "GridSearch_table_plot(grid_model, \"kernel\", negative=False, display_all_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11910328-3f03-4c5f-b83c-02511d759d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report best hyperparameters\n",
    "print('Best Cost parameter : '+ str(grid_model.best_estimator_.C))\n",
    "print('Best epsilon parameter : '+ str(grid_model.best_estimator_.epsilon))\n",
    "print('Best kernel parameter : '+ str(grid_model.best_estimator_.kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e69055-4dd8-4f4e-a202-1dbe1eeeaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = grid_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a36793-0eb0-4892-8748-b9f6a8bc737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check in-sample performance\n",
    "print('In-sample R2 Score : '+ str(r2_score(np.exp(y),np.exp(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716bb87-5c76-41a2-8512-7a6510e8c203",
   "metadata": {},
   "source": [
    "## Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df27b89-a416-4b0f-b898-0d11c566447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chosen model on entire train dataframe\n",
    "model = Lasso(random_state=42, alpha = 1.5 )\n",
    "model.fit(df.drop('price', axis=1), df['price'])\n",
    "\n",
    "# predict test values\n",
    "test_predictions = model.predict(df_test)\n",
    "\n",
    "# create csv file with results to submit\n",
    "test_prediction_submit = pd.DataFrame({\"id\": df_test_id[\"id\"],  \"price\": test_predictions})\n",
    "test_prediction_submit.to_csv(\"test_submit.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
